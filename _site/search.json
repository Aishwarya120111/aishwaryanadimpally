[
  {
    "objectID": "projects.html",
    "href": "projects.html",
    "title": "Projects",
    "section": "",
    "text": "Description: Developed a framework for wrangling data to extract drilling trends over 10 years on a global scale, with an intuitive application for visualization, and built a spatial-temporal trend prediction of mining locations by identifying patterns.\nTechnologies/Libraries Used: Python, DASH, Plotly, HTML, CSS, H3, sklearn, geojson\nLink: Due to the confidentiality of data, I am not disclosing the project GitHub repository.\nGIF:"
  },
  {
    "objectID": "projects.html#capstone-project---riotinto",
    "href": "projects.html#capstone-project---riotinto",
    "title": "Projects",
    "section": "",
    "text": "Description: Developed a framework for wrangling data to extract drilling trends over 10 years on a global scale, with an intuitive application for visualization, and built a spatial-temporal trend prediction of mining locations by identifying patterns.\nTechnologies/Libraries Used: Python, DASH, Plotly, HTML, CSS, H3, sklearn, geojson\nLink: Due to the confidentiality of data, I am not disclosing the project GitHub repository.\nGIF:"
  },
  {
    "objectID": "projects.html#home-scope-ubc-mds-coursework---dashboard",
    "href": "projects.html#home-scope-ubc-mds-coursework---dashboard",
    "title": "Projects",
    "section": "Home Scope (UBC MDS Coursework - Dashboard)",
    "text": "Home Scope (UBC MDS Coursework - Dashboard)\n\nDescription: HomeScope is an analytical platform dedicated to illuminating the real estate market’s complexities. Aimed at stakeholders such as investors, developers, market analysts, and urban planners, it provides actionable insights through the careful analysis of pivotal variables influencing property values.\nTechnologies Used: Python, DASH, Altair, Plotly\nLink: GitHub Repository\nGIF:"
  },
  {
    "objectID": "projects.html#job-search-application",
    "href": "projects.html#job-search-application",
    "title": "Projects",
    "section": "Job Search Application",
    "text": "Job Search Application\n\nDescription: Developed a job search application using Google Generative AI to simplify the job search process. The application provides custom matching scores, identifies missing skills, and includes job application links based on each uploaded resume.\nTechnologies Used: Python, Google Generative AI, Streamlit\nLink: GitHub Repository\nGIF:"
  },
  {
    "objectID": "projects.html#chatbot-conversations-classfication-application",
    "href": "projects.html#chatbot-conversations-classfication-application",
    "title": "Projects",
    "section": "Chatbot Conversations Classfication Application",
    "text": "Chatbot Conversations Classfication Application\n\nDescription: This Streamlit application allows users to upload an Excel file containing chatbot queries, classify them using a pre-trained BERT model, and download the predictions in an Excel file.This tool is particularly useful for teams in customer support, data analytics, and natural language processing who need efficient query classification and analysis.\nTechnologies Used: Python, Transformers, Streamlit, Pandas, Torch, Scikit-Learn\nLink: GitHub Repository\nGIF:"
  },
  {
    "objectID": "projects.html#churn-insights-analysis-prediction",
    "href": "projects.html#churn-insights-analysis-prediction",
    "title": "Projects",
    "section": "Churn Insights Analysis & prediction",
    "text": "Churn Insights Analysis & prediction\n\nDescription: Developed a framework for performing ETL and data cleaning in PostgreSQL, followed by transforming data and creating enhanced visualizations in Tableau. Built and evaluated machine learning models, including KNN, Decision Tree, Random Forest, RBF SVM, and Logistic Regression, to predict outcomes, selecting the best model after thorough EDA.\nTechnologies Used: Python (Scikit-Learn, Altair, Plotly, PyTorch), PostgreSQL, Tableau\nLink: GitHub Repository\nGIF:"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About Me",
    "section": "",
    "text": "After completing my undergraduate degree, I embarked on an exciting career at Tata Consultancy Services (TCS), where I spent over five years honing my skills in chatbot development, data analysis, and machine learning. At TCS, I had the privilege of leading a talented team of developers, and together, we built innovative chatbots that significantly improved customer support efficiency and user experience."
  },
  {
    "objectID": "about.html#what-i-do",
    "href": "about.html#what-i-do",
    "title": "About Me",
    "section": "What I Do",
    "text": "What I Do\nI specialize in:\n\nBuilding Intelligent Chatbots: Creating chatbots using platforms like AWS, Azure, Google and AVAAMO, integrating them seamlessly into client systems.\nData Analysis and Visualization: Utilizing tools like Power BI, Tableau, and Python to turn complex data into clear, actionable insights.\nMachine Learning and AI Development: Developing machine learning models to solve real-world problems, with a focus on NLP and generative AI technologies."
  },
  {
    "objectID": "about.html#my-journey-in-data-science-and-ai",
    "href": "about.html#my-journey-in-data-science-and-ai",
    "title": "About Me",
    "section": "My Journey in Data Science and AI",
    "text": "My Journey in Data Science and AI\nMy curiosity and drive for continuous learning led me to pursue a Master’s degree in Data Science at the University of British Columbia. Here, I delved deeper into the realms of machine learning, natural language processing, and AI development. One of my most fulfilling projects was with Rio Tinto Exploration, where I developed a sophisticated data visualization tool and predictive models to identify mining trends."
  },
  {
    "objectID": "about.html#professional-experience",
    "href": "about.html#professional-experience",
    "title": "About Me",
    "section": "Professional Experience",
    "text": "Professional Experience\n\nLead Developer & Analyst, Tata Consultancy Services (Feb 2022 – July 2023)\n\nDeveloped a chatbot in AVAMMO using Python and NodeJS for a client product, supporting users with product documentation, installation, and technical issues.\nExtracted and analyzed data from SQL & chatbot logs, visualizing it using Power BI to help clients improve customer satisfaction.\nLed and trained a team of 4 developers, ensuring efficient project delivery and skill advancement.\nAchieved a 40% reduction in customer-raised issues on the support portal by developing a BOT that independently handled all L1 cases.\n\n\n\nChatbot Developer, Tata Consultancy Services (July 2020 – Jan 2022)\n\nCollaborated with the Digital Center of Excellence (CoE) team to develop chatbots across Azure, AWS, and Google platforms using Python.\nDeveloped a universal bot that streamlined three different bots, significantly improving cost efficiency for infrastructure maintenance.\nReceived the Best Employee of the Year award for the development of the universal bot.\n\n\n\nLead AWS Developer, Tata Consultancy Services (Jan 2019 – June 2020)\n\nManaged business requirements, bot design, conversation analysis, and stakeholder reporting while supporting the team in coding and problem-solving.\nDeveloped conversation flows for chatbots using Python, integrated with AWS services, and implemented CI/CD pipelines with Jenkins and AWS CodePipeline.\n\n\n\nApplication Administrator, Tata Consultancy Services (July 2018 – Dec 2018)\n\nAcquired the ability to translate business requirements into precise technical specifications, while also proficiently analyzing data using SQL, VBA, and Excel/Pivot tables for effective visualization.\nManaged server upgrades, tool licensing, and delivered projects with effective stakeholder communication."
  },
  {
    "objectID": "about.html#capstone-project",
    "href": "about.html#capstone-project",
    "title": "About Me",
    "section": "Capstone Project",
    "text": "Capstone Project\n\nData Scientist, Rio Tinto Exploration (Vancouver)\n\nDeveloped a framework and DASH application to wrangle data and extract drilling trends over a period of 10 years globally, providing intuitive visualization.\nBuilt a spatial-temporal trend prediction model to identify patterns in mining locations using a multi-output supervised learning model."
  },
  {
    "objectID": "about.html#achievements-and-skills",
    "href": "about.html#achievements-and-skills",
    "title": "About Me",
    "section": "Achievements and Skills",
    "text": "Achievements and Skills\nThroughout my career, I’ve been recognized for my technical acumen and leadership abilities. Some highlights include:\n\nLeading the development of a chatbot that reduced customer support queries by 40%.\nReceiving the Best Employee of the Year award for developing a universal bot that streamlined multiple systems, enhancing efficiency.\nEarning the Academic Excellence Award during my undergraduate studies."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Aishwarya Nadimpally",
    "section": "",
    "text": "Hi, I’m Aishwarya Nadimpally, a skilled Data Scientist and AI Developer with a Master’s degree in Data Science and over five years of experience in building innovative chatbots and AI solutions. I specialize in leveraging data to drive insights and develop intelligent systems that enhance user experiences and optimize business operations.\nMy expertise spans across various roles, including Data Analyst, Data Scientist, Conversation AI Developer, and Generative AI Developer. I have a strong background in data analysis, machine learning, and natural language processing, which allows me to create sophisticated AI models and applications.\n\n\n\n\nAbout\n\n\nLearn more about me\n\n \n\nProjects\n\n\nCheckout My Work\n\n \n\nResume\n\n\nView my resume"
  }
]